#!/usr/bin/env python3
"""
ê°„ë‹¨í•œ RAG í†µí•© í…ŒìŠ¤íŠ¸
ê¸°ì¡´ develop_lee êµ¬ì¡°ì—ì„œ RAG ê¸°ëŠ¥ì´ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸
"""

import asyncio
import os
import sys
import json
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
voice_analysis_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.append(voice_analysis_root)

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (í…ŒìŠ¤íŠ¸ìš©)
os.environ.setdefault('GOOGLE_CLOUD_PROJECT', 'senior-mhealth-test')

async def test_vector_store_manager():
    """ë²¡í„°ìŠ¤í† ì–´ ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸"""
    print("ğŸ” ë²¡í„°ìŠ¤í† ì–´ ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    try:
        from rag.core.vector_store_manager import FirebaseStorageVectorStore
        
        # Firebase ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ë¡œì»¬ ê¸°ëŠ¥ë§Œ í…ŒìŠ¤íŠ¸
        vector_store = FirebaseStorageVectorStore()
        
        # ë¡œì»¬ ì„ë² ë”© íŒŒì¼ í™•ì¸
        embeddings_path = vector_store.local_embeddings_path
        print(f"ì„ë² ë”© íŒŒì¼ ê²½ë¡œ: {embeddings_path}")
        
        if os.path.exists(embeddings_path):
            file_size = os.path.getsize(embeddings_path)
            print(f"âœ… ì„ë² ë”© íŒŒì¼ ì¡´ì¬ (í¬ê¸°: {file_size:,} bytes)")
            
            # ë¡œì»¬ ì„ë² ë”© ë¡œë“œ í…ŒìŠ¤íŠ¸
            await vector_store._load_local_embeddings()
            
            if vector_store._embedding_cache:
                print(f"âœ… ì„ë² ë”© ìºì‹œ ë¡œë“œ ì„±ê³µ: {len(vector_store._embedding_cache)}ê°œ ë¬¸ì„œ")
                
                # ì²« ë²ˆì§¸ ë¬¸ì„œ êµ¬ì¡° í™•ì¸
                first_doc = vector_store._embedding_cache[0]
                print("ğŸ“ ì²« ë²ˆì§¸ ë¬¸ì„œ êµ¬ì¡°:")
                for key in first_doc.keys():
                    if key == 'embedding':
                        print(f"  - {key}: ë²¡í„° (ê¸¸ì´: {len(first_doc[key])})")
                    else:
                        value = first_doc[key]
                        if isinstance(value, str) and len(value) > 50:
                            print(f"  - {key}: {value[:50]}...")
                        else:
                            print(f"  - {key}: {value}")
                
                return True
            else:
                print("âŒ ì„ë² ë”© ìºì‹œ ë¡œë“œ ì‹¤íŒ¨")
                return False
        else:
            print(f"âŒ ì„ë² ë”© íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {embeddings_path}")
            return False
            
    except Exception as e:
        print(f"âŒ ë²¡í„°ìŠ¤í† ì–´ ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

async def test_document_search():
    """ë¬¸ì„œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” ë¬¸ì„œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    try:
        from rag.core.vector_store_manager import FirebaseStorageVectorStore
        
        vector_store = FirebaseStorageVectorStore()
        
        # OpenAI API í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸
        if not os.getenv('OPENAI_API_KEY'):
            print("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ. ê²€ìƒ‰ ê¸°ëŠ¥ì€ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return False
        
        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
        test_queries = [
            "ìš°ìš¸ì¦ ì¦ìƒê³¼ ì§„ë‹¨",
            "ë…¸ì¸ ì¸ì§€ ê¸°ëŠ¥ ì €í•˜",
            "ìˆ˜ë©´ ì¥ì•  ì¹˜ë£Œ ë°©ë²•"
        ]
        
        for query in test_queries:
            print(f"\nê²€ìƒ‰ ì¿¼ë¦¬: '{query}'")
            try:
                results = await vector_store.search_similar_documents(
                    query_text=query,
                    max_results=3,
                    similarity_threshold=0.5  # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë‚®ì€ ì„ê³„ê°’ ì‚¬ìš©
                )
                
                if results:
                    print(f"âœ… {len(results)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ë¨")
                    for i, doc in enumerate(results, 1):
                        similarity = doc.get('similarity', 0)
                        content = doc.get('content', doc.get('text', ''))[:100]
                        print(f"  {i}. ìœ ì‚¬ë„: {similarity:.3f} | ë‚´ìš©: {content}...")
                else:
                    print("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                    
            except Exception as e:
                print(f"âŒ ì¿¼ë¦¬ '{query}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ë¬¸ì„œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

async def test_rag_enhanced_analyzer():
    """RAG ê°•í™” ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§  RAG ê°•í™” ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    try:
        from rag.core.rag_enhanced_analyzer import RAGEnhancedTextAnalyzer
        
        # RAG ê¸°ëŠ¥ì„ ë¹„í™œì„±í™”í•˜ê³  ê¸°ë³¸ ë¶„ì„ê¸°ë¡œ í…ŒìŠ¤íŠ¸ (API í‚¤ ì—†ì´ë„ ì‘ë™)
        analyzer = RAGEnhancedTextAnalyzer(use_rag=False)
        print("âœ… RAG ê°•í™” ë¶„ì„ê¸° ì´ˆê¸°í™” ì„±ê³µ (RAG ë¹„í™œì„±í™” ëª¨ë“œ)")
        
        # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
        test_text = "ìš”ì¦˜ ì ì„ ì˜ ëª» ìê³ , ê¸°ë¶„ë„ ìš°ìš¸í•´ìš”. ê¸°ì–µë ¥ë„ ì˜ˆì „ ê°™ì§€ ì•Šê³  ì§‘ì¤‘í•˜ê¸°ê°€ ì–´ë ¤ì›Œìš”."
        
        print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸: {test_text}")
        
        # ê¸°ë³¸ ë¶„ì„ í…ŒìŠ¤íŠ¸ (RAG ì—†ì´)
        result = await analyzer.analyze(test_text)
        
        if result.get('status') == 'success':
            print("âœ… ê¸°ë³¸ í…ìŠ¤íŠ¸ ë¶„ì„ ì„±ê³µ")
            indicators = result.get('analysis', {}).get('indicators', {})
            print("ğŸ“Š ë¶„ì„ ì§€í‘œ:")
            for key, value in indicators.items():
                print(f"  - {key}: {value}")
        else:
            print(f"âš ï¸ ê¸°ë³¸ ë¶„ì„ ê²°ê³¼: {result.get('status')} - {result.get('error', 'Unknown error')}")
        
        # RAG í™œì„±í™” í…ŒìŠ¤íŠ¸ (API í‚¤ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
        if os.getenv('OPENAI_API_KEY'):
            print("\nğŸ” RAG í™œì„±í™” í…ŒìŠ¤íŠ¸...")
            rag_analyzer = RAGEnhancedTextAnalyzer(use_rag=True)
            
            if rag_analyzer.use_rag:
                print("âœ… RAG ê¸°ëŠ¥ í™œì„±í™”ë¨")
                
                rag_result = await rag_analyzer.analyze_with_rag(test_text)
                
                if rag_result.get('rag_metadata'):
                    print("âœ… RAG ë©”íƒ€ë°ì´í„° í¬í•¨ë¨")
                    rag_meta = rag_result['rag_metadata']
                    print(f"  - RAG ì‚¬ìš©: {rag_meta.get('rag_used')}")
                    print(f"  - ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸: {rag_meta.get('context_count')}ê°œ")
                
        return True
        
    except Exception as e:
        print(f"âŒ RAG ê°•í™” ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸš€ RAG í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 70)
    
    results = []
    
    # 1. ë²¡í„°ìŠ¤í† ì–´ ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸
    results.append(await test_vector_store_manager())
    
    # 2. ë¬¸ì„œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    results.append(await test_document_search())
    
    # 3. RAG ê°•í™” ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸
    results.append(await test_rag_enhanced_analyzer())
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 70)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 70)
    
    test_names = [
        "ë²¡í„°ìŠ¤í† ì–´ ë§¤ë‹ˆì €",
        "ë¬¸ì„œ ê²€ìƒ‰",
        "RAG ê°•í™” ë¶„ì„ê¸°"
    ]
    
    passed = 0
    for i, (name, result) in enumerate(zip(test_names, results)):
        status = "âœ… í†µê³¼" if result else "âŒ ì‹¤íŒ¨"
        print(f"{i+1}. {name}: {status}")
        if result:
            passed += 1
    
    print(f"\nì „ì²´ ê²°ê³¼: {passed}/{len(results)} í…ŒìŠ¤íŠ¸ í†µê³¼")
    
    if passed == len(results):
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    return passed == len(results)

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)